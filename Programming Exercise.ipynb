{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-label Classification problem\n",
    "\n",
    "##### Requirements:\n",
    "scikit-learn==0.18.2<br>\n",
    "pandas==0.23.3<br>\n",
    "numpy==1.13.1<br>\n",
    "nltk==3.3<br>\n",
    "matplotlib==2.0.2<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this multi-label classification problem, I have concatenated the intent and class labels and trained the model. \n",
    "\n",
    "The maximum accuracy achieved is 0.664221218962. \n",
    "\n",
    "Also in the last cell of this notebook, you can see the Classification report with Precision and recall per class and intent for the best model.\n",
    "\n",
    "I have documented below the accuracies and the corresponding models and methods used.\n",
    "\n",
    "I have noticed that pre-processing and MultiLabelBinarizer improved the Classifier performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "- BinaryRelevance(RandomForestClassifier()) \n",
    "Accuracy =  0.348758465011\n",
    "Hamming Loss =  0.021231739000809234\n",
    "\n",
    "- LabelPowerset(RandomForestClassifier())\n",
    "Accuracy =  0.654063205418\n",
    "Hamming Loss =  0.02340389284041058\n",
    "\n",
    "- ClassifierChain(RandomForestClassifier())\n",
    "Accuracy =  0.437358916479\n",
    "Hamming Loss =  0.02069934835384812\n",
    "\n",
    "**********************************************************************************************************************************\n",
    "- Best Accuracy achieved:\n",
    "\n",
    "- SVM + MultiLabelBinarizer + Preprocessing + no stop words removal\n",
    "\n",
    "model: model_20180803_153406.pkl\n",
    "\n",
    "Grid search chosen parameters are:  {'tfidf__use_idf': True, 'vect__ngram_range': (1, 2), 'clf-svm__estimator__C': 10}\n",
    "Accuracy with Grid search parameters:  0.5988323603\n",
    "Accuracy (test):  0.664221218962\n",
    "Hamming Loss =  0.012021380808381959\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "intent = []\n",
    "label = []\n",
    "ques = []\n",
    "label_intent = []\n",
    "\n",
    "def load_data(train_data_path):\n",
    "    \n",
    "    '''Import data'''\n",
    "\n",
    "    '''Number of samples = 15452'''\n",
    "    \n",
    "    global intent\n",
    "    global label\n",
    "    global ques\n",
    "    global label_intent\n",
    "\n",
    "    data_array = []\n",
    "\n",
    "    with open(data_path, 'r') as csvfile:\n",
    "        data_reader = csv.reader(csvfile)\n",
    "        for row in data_reader:\n",
    "#             print('1:', row)\n",
    "            data_array.append(row[0])\n",
    "\n",
    "    '''Structure the imported data'''\n",
    "    \n",
    "    for i,d in enumerate(data_array):\n",
    "        temp = d.split(':')\n",
    "        intent.append(temp[0])\n",
    "        lis = temp[1].split(' ')\n",
    "        label.append(lis[0])\n",
    "        ques.append(' '.join(lis[1:]))\n",
    "        label_intent.append([temp[0], lis[0]])\n",
    "        \n",
    "data_path = 'E:/aaaML Projects/data/aisera_dataset/training.data'\n",
    "\n",
    "load_data(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Remove redundant data'''\n",
    "\n",
    "questions = []\n",
    "intent_set = []\n",
    "label_set = []\n",
    "label_intent_set = []\n",
    "\n",
    "for i in range(len(ques)):\n",
    "    if ques[i] not in questions:\n",
    "        questions.append(ques[i])\n",
    "        intent_set.append(intent[i])\n",
    "        label_set.append(label[i])\n",
    "        label_intent_set.append(label_intent[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  intent   label\n",
      "0   DESC  manner\n",
      "1   ENTY  cremat\n",
      "2   DESC  manner\n",
      "3   ENTY  animal\n",
      "4   ABBR     exp\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'intent':intent,'label':label})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>abb</th>\n",
       "      <th>animal</th>\n",
       "      <th>body</th>\n",
       "      <th>city</th>\n",
       "      <th>code</th>\n",
       "      <th>color</th>\n",
       "      <th>count</th>\n",
       "      <th>country</th>\n",
       "      <th>cremat</th>\n",
       "      <th>currency</th>\n",
       "      <th>...</th>\n",
       "      <th>substance</th>\n",
       "      <th>symbol</th>\n",
       "      <th>techmeth</th>\n",
       "      <th>temp</th>\n",
       "      <th>termeq</th>\n",
       "      <th>title</th>\n",
       "      <th>veh</th>\n",
       "      <th>volsize</th>\n",
       "      <th>weight</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intent</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABBR</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DESC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTY</th>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>595</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>31</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>376</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "label   abb  animal  body  city  code  color  count  country  cremat  \\\n",
       "intent                                                                 \n",
       "ABBR     46       0     0     0     0      0      0        0       0   \n",
       "DESC      0       0     0     0     0      0      0        0       0   \n",
       "ENTY      0     365    54     0     0    119      0        0     595   \n",
       "HUM       0       0     0     0     0      0      0        0       0   \n",
       "LOC       0       0     0   376     0      0      0      425       0   \n",
       "NUM       0       0     0     0    22      0    985        0       0   \n",
       "\n",
       "label   currency  ...   substance  symbol  techmeth  temp  termeq  title  veh  \\\n",
       "intent            ...                                                           \n",
       "ABBR           0  ...           0       0         0     0       0      0    0   \n",
       "DESC           0  ...           0       0         0     0       0      0    0   \n",
       "ENTY           6  ...         124      31       111     0     271      0   68   \n",
       "HUM            0  ...           0       0         0     0       0     67    0   \n",
       "LOC            0  ...           0       0         0     0       0      0    0   \n",
       "NUM            0  ...           0       0         0    15       0      0    0   \n",
       "\n",
       "label   volsize  weight  word  \n",
       "intent                         \n",
       "ABBR          0       0     0  \n",
       "DESC          0       0     0  \n",
       "ENTY          0       0    71  \n",
       "HUM           0       0     0  \n",
       "LOC           0       0     0  \n",
       "NUM          32      23     0  \n",
       "\n",
       "[6 rows x 47 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.crosstab(df['intent'],df['label'])\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "'''To encode the target label and intent: Method 1'''\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "temp = np.array(label_set)\n",
    "label_encode = to_categorical(encoder.fit_transform(temp.astype(str)))\n",
    "\n",
    "temp = np.array(intent_set)\n",
    "intent_encode = to_categorical(encoder.fit_transform(temp.astype(str)))\n",
    "\n",
    "y = np.concatenate((intent_encode, label_encode), axis=1) # shape: samples x labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "'''To encode the target label and intent: Method 2 is better than Method 1'''\n",
    "\n",
    "multilabel_binarizer = MultiLabelBinarizer(sparse_output = True)\n",
    "y = multilabel_binarizer.fit_transform(label_intent_set)\n",
    "classes_list = multilabel_binarizer.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the input text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from datetime import datetime\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def pre_process_data(words):\n",
    "    ''' Pre process text data: Does Lemmatization, strips case, punctuation, converts number to words and stopwords'''\n",
    "    \n",
    "    word_tokens = [word.lower() for word in word_tokenize(words)]\n",
    "    \n",
    "    # To lower case\n",
    "    word_lower = [word.lower() for word in word_tokens] \n",
    "    \n",
    "    # Remove punctuations\n",
    "    table = str.maketrans('','', string.punctuation)\n",
    "    word_nopunct = [w.translate(table) for w in word_lower]\n",
    "    \n",
    "    # Remove non-alphabetic tokens\n",
    "    word_list = [word for word in word_nopunct if word.isalpha()] \n",
    "    \n",
    "    # Remove stopwords\n",
    "#     stopword_list = set(stopwords.words('english'))\n",
    "#     word_stopw = [w for w in word_list if not w in stopword_list]\n",
    "    \n",
    "    # Lemmatization\n",
    "    wnl = WordNetLemmatizer()\n",
    "    word_final = [wnl.lemmatize(w) for w in word_list]\n",
    "    \n",
    "    return word_final\n",
    "\n",
    "'''Pre-process training dataset for X''' \n",
    "\n",
    "X = [] \n",
    "for q in questions:\n",
    "    X.append(' '.join(pre_process_data(q)))\n",
    "    \n",
    "cv = CountVectorizer()\n",
    "X_cv = cv.fit_transform(X)\n",
    "\n",
    "tf_idf = TfidfTransformer()\n",
    "X_tf = tf_idf.fit_transform(X_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Grid search...\n",
      "Grid search chosen parameters are:  {'tfidf__use_idf': True, 'vect__ngram_range': (1, 2), 'clf-svm__estimator__C': 10}\n",
      "Accuracy with Grid search parameters:  0.5988323603\n",
      "Accuracy (test):  0.664221218962\n",
      "Model saved as Pickle file successfully: model_20180803_153406.pkl\n",
      "Intent:  HUM \n",
      "Label:  desc\n"
     ]
    }
   ],
   "source": [
    "def Grid_search(svm_pipeline, svm_parameters, X_train, y_train):\n",
    "    \n",
    "    ''' Performs Grid search to find optimal values for model parameters'''\n",
    "    \n",
    "    print ('Doing Grid search...')\n",
    "    gs_svm = GridSearchCV(svm_pipeline, param_grid=svm_parameters, n_jobs=-1)\n",
    "    gs_svm = gs_svm.fit(X_train, y_train)\n",
    "    print (\"Grid search chosen parameters are: \", gs_svm.best_params_)\n",
    "    print (\"Accuracy with Grid search parameters: \", gs_svm.best_score_)\n",
    "    return gs_svm\n",
    "\n",
    "def train_model(X,y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "    text_svmpipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                                 ('tfidf', TfidfTransformer()),\n",
    "                                 ('clf-svm', OneVsRestClassifier(LinearSVC()))])\n",
    "\n",
    "    svm_parameters = [{'vect__ngram_range': [(1, 1), (1, 2), (1,3)], 'tfidf__use_idf': (True, False),'clf-svm__estimator__C': [0.001, 0.01, 0.1, 1, 10]}]\n",
    "\n",
    "    svm_model = Grid_search(text_svmpipeline, svm_parameters, X_train, y_train)\n",
    "\n",
    "    # train\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # predict\n",
    "    result = svm_model.score(X_test, y_test)\n",
    "    print('Accuracy (test): ', result)\n",
    "    return X_test, y_test, svm_model \n",
    "\n",
    "def save_model(model_object):\n",
    "    ''' Saves the trained model with timestamp'''\n",
    "    \n",
    "    try:\n",
    "        joblib.dump(model_object, 'model_{}.pkl'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\")))\n",
    "        print (\"Model saved as Pickle file successfully:\", 'model_{}.pkl'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\")))\n",
    "    except Exception as error:\n",
    "        print (\"Error saving model\")\n",
    "        print (error)\n",
    "\n",
    "def load_model(model_path):    \n",
    "    ''' Loads the trained and saved model'''\n",
    "    \n",
    "    loaded_model = joblib.load(model_path)\n",
    "    return loaded_model\n",
    "\n",
    "def predict_intent(question):\n",
    "    '''To predict the classes of a question'''\n",
    "    \n",
    "#     svm_model = load_model(model_path)\n",
    "    \n",
    "    p = svm_model.predict([question]) # Predict the classes\n",
    "    _, classes = p.nonzero() # unpack the sparse matrix\n",
    "    \n",
    "    return classes_list[classes[0]], classes_list[classes[1]]\n",
    " \n",
    "X_test, y_test,svm_model = train_model(X,y)\n",
    "save_model(svm_model)\n",
    "\n",
    "t, l = predict_intent('Who is Lakers?')\n",
    "print('Intent: ', t, '\\nLabel: ', l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.664221218962\n",
      "Hamming Loss =  0.012021380808381959\n",
      "Classification Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ABBR       0.89      0.71      0.79        35\n",
      "       DESC       0.87      0.87      0.87       387\n",
      "       ENTY       0.83      0.72      0.77       400\n",
      "        HUM       0.93      0.82      0.87       390\n",
      "        LOC       0.94      0.83      0.88       281\n",
      "        NUM       0.97      0.90      0.93       279\n",
      "        abb       1.00      0.43      0.60         7\n",
      "     animal       0.89      0.46      0.60        35\n",
      "       body       0.00      0.00      0.00         4\n",
      "       city       0.82      0.80      0.81        40\n",
      "       code       0.00      0.00      0.00         3\n",
      "      color       1.00      0.87      0.93        23\n",
      "      count       0.98      0.96      0.97       114\n",
      "    country       0.89      0.98      0.93        48\n",
      "     cremat       0.98      0.61      0.75        76\n",
      "   currency       0.00      0.00      0.00         0\n",
      "       date       0.94      0.88      0.91        72\n",
      "        def       0.80      0.88      0.84       143\n",
      "       desc       0.84      0.55      0.67       105\n",
      "     dismed       0.85      0.78      0.82        37\n",
      "       dist       1.00      0.62      0.76        13\n",
      "      event       1.00      0.27      0.43        11\n",
      "        exp       0.79      0.68      0.73        28\n",
      "       food       1.00      0.38      0.55        34\n",
      "         gr       0.82      0.52      0.64        61\n",
      "        ind       0.88      0.83      0.86       313\n",
      "     instru       1.00      0.67      0.80         3\n",
      "       lang       1.00      1.00      1.00         2\n",
      "     letter       0.00      0.00      0.00         2\n",
      "     manner       0.97      0.99      0.98        91\n",
      "      money       0.83      0.75      0.79        20\n",
      "      mount       1.00      0.67      0.80         6\n",
      "        ord       0.00      0.00      0.00         1\n",
      "      other       0.91      0.59      0.72       241\n",
      "       perc       1.00      0.22      0.36         9\n",
      "     period       0.79      0.79      0.79        24\n",
      "      plant       1.00      0.25      0.40         4\n",
      "    product       0.75      0.46      0.57        13\n",
      "     reason       0.98      0.81      0.89        58\n",
      "   religion       0.00      0.00      0.00         2\n",
      "      speed       1.00      1.00      1.00         1\n",
      "      sport       0.92      0.58      0.71        19\n",
      "      state       0.84      0.76      0.80        21\n",
      "  substance       1.00      0.57      0.73         7\n",
      "     symbol       1.00      0.40      0.57         5\n",
      "   techmeth       0.80      0.29      0.42        14\n",
      "       temp       1.00      1.00      1.00         3\n",
      "     termeq       0.58      0.45      0.51        31\n",
      "      title       1.00      0.33      0.50         6\n",
      "        veh       1.00      0.25      0.40         8\n",
      "    volsize       1.00      1.00      1.00         3\n",
      "     weight       1.00      1.00      1.00         2\n",
      "       word       0.67      0.44      0.53         9\n",
      "\n",
      "avg / total       0.89      0.77      0.82      3544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Archana\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Archana\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_test,y_pred))\n",
    "\n",
    "print(\"Hamming Loss = \", metrics.hamming_loss(y_test, y_pred))\n",
    "\n",
    "print('Classification Report: ')\n",
    "print(classification_report(y_test,y_pred, target_names = classes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage error 17.1015801354\n",
      "Label ranking loss 0.228571902802\n",
      "Label ranking average precision score 0.756267125232\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import coverage_error\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "import pickle \n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "def load_model(model_path):    \n",
    "    ''' Loads the trained and saved model'''\n",
    "    \n",
    "    pkl_file = open('class_list.pkl', 'rb')\n",
    "    classes_list = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    \n",
    "    loaded_model = joblib.load(model_path)\n",
    "    return classes_list, loaded_model\n",
    "\n",
    "# classes_list, svm_model = load_model('model_20180801_222822.pkl')\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print('Coverage error', coverage_error(y_test.todense(), y_pred.todense()))\n",
    "print('Label ranking loss', label_ranking_loss(y_test, y_pred.todense()))\n",
    "print('Label ranking average precision score', label_ranking_average_precision_score(y_test.todense(), y_pred.todense()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Other models used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.437358916479\n",
      "Hamming Loss =  0.02069934835384812\n",
      "Classification Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ABBR       0.79      0.41      0.54        27\n",
      "       DESC       0.88      0.54      0.67       388\n",
      "       ENTY       0.78      0.48      0.60       401\n",
      "        HUM       0.92      0.64      0.76       402\n",
      "        LOC       0.85      0.76      0.80       259\n",
      "        NUM       0.90      0.77      0.83       295\n",
      "        abb       0.00      0.00      0.00         7\n",
      "     animal       0.89      0.23      0.36        35\n",
      "       body       0.00      0.00      0.00         7\n",
      "       city       0.92      0.27      0.42        44\n",
      "       code       0.00      0.00      0.00         0\n",
      "      color       1.00      0.08      0.14        13\n",
      "      count       0.99      0.87      0.92       120\n",
      "    country       0.88      0.68      0.77        44\n",
      "     cremat       0.74      0.20      0.32        69\n",
      "   currency       0.00      0.00      0.00         2\n",
      "       date       0.89      0.51      0.65        78\n",
      "        def       0.81      0.63      0.70       139\n",
      "       desc       0.97      0.34      0.50       101\n",
      "     dismed       1.00      0.65      0.78        31\n",
      "       dist       0.00      0.00      0.00        10\n",
      "      event       0.00      0.00      0.00        21\n",
      "        exp       0.77      0.50      0.61        20\n",
      "       food       1.00      0.12      0.22        32\n",
      "         gr       0.62      0.10      0.18        49\n",
      "        ind       0.84      0.65      0.73       328\n",
      "     instru       1.00      0.25      0.40         4\n",
      "       lang       1.00      0.12      0.22         8\n",
      "     letter       0.00      0.00      0.00         3\n",
      "     manner       0.96      0.52      0.68        92\n",
      "      money       0.86      0.26      0.40        23\n",
      "      mount       0.00      0.00      0.00         7\n",
      "        ord       0.00      0.00      0.00         1\n",
      "      other       0.78      0.46      0.58       215\n",
      "       perc       0.00      0.00      0.00        11\n",
      "     period       0.88      0.33      0.48        21\n",
      "      plant       0.00      0.00      0.00         3\n",
      "    product       0.00      0.00      0.00        11\n",
      "     reason       0.95      0.51      0.66        73\n",
      "   religion       0.00      0.00      0.00         3\n",
      "      speed       0.00      0.00      0.00         4\n",
      "      sport       1.00      0.21      0.35        19\n",
      "      state       1.00      0.29      0.45        24\n",
      "  substance       0.00      0.00      0.00        16\n",
      "     symbol       0.00      0.00      0.00         2\n",
      "   techmeth       0.00      0.00      0.00        12\n",
      "       temp       0.00      0.00      0.00         5\n",
      "     termeq       0.00      0.00      0.00        29\n",
      "      title       1.00      0.12      0.22         8\n",
      "        veh       0.00      0.00      0.00        12\n",
      "    volsize       0.00      0.00      0.00         5\n",
      "     weight       0.00      0.00      0.00         3\n",
      "       word       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.82      0.53      0.63      3544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Archana\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Archana\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tf, y, test_size=0.33)\n",
    "\n",
    "classifier = ClassifierChain(RandomForestClassifier())\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_test,predictions))\n",
    "\n",
    "print(\"Hamming Loss = \", metrics.hamming_loss(y_test, predictions))\n",
    "\n",
    "print('Classification Report: ')\n",
    "print(classification_report(y_test,predictions, target_names = classes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.654063205418\n",
      "Hamming Loss =  0.02340389284041058\n",
      "Classification Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ABBR       0.71      0.44      0.55        27\n",
      "       DESC       0.71      0.85      0.77       388\n",
      "       ENTY       0.69      0.48      0.56       401\n",
      "        HUM       0.65      0.86      0.74       402\n",
      "        LOC       0.73      0.80      0.77       259\n",
      "        NUM       0.94      0.65      0.77       295\n",
      "        abb       1.00      0.14      0.25         7\n",
      "     animal       0.59      0.37      0.46        35\n",
      "       body       1.00      0.14      0.25         7\n",
      "       city       0.90      0.84      0.87        44\n",
      "       code       0.00      0.00      0.00         0\n",
      "      color       1.00      1.00      1.00        13\n",
      "      count       0.90      0.92      0.91       120\n",
      "    country       0.88      0.95      0.91        44\n",
      "     cremat       0.55      0.59      0.57        69\n",
      "   currency       1.00      0.50      0.67         2\n",
      "       date       0.84      0.60      0.70        78\n",
      "        def       0.64      0.86      0.74       139\n",
      "       desc       0.50      0.55      0.53       101\n",
      "     dismed       0.92      0.74      0.82        31\n",
      "       dist       1.00      0.10      0.18        10\n",
      "      event       0.33      0.05      0.08        21\n",
      "        exp       0.62      0.50      0.56        20\n",
      "       food       0.69      0.28      0.40        32\n",
      "         gr       0.55      0.35      0.42        49\n",
      "        ind       0.57      0.85      0.69       328\n",
      "     instru       1.00      0.25      0.40         4\n",
      "       lang       1.00      0.50      0.67         8\n",
      "     letter       0.00      0.00      0.00         3\n",
      "     manner       0.77      0.97      0.86        92\n",
      "      money       0.67      0.09      0.15        23\n",
      "      mount       0.60      0.43      0.50         7\n",
      "        ord       0.00      0.00      0.00         1\n",
      "      other       0.55      0.58      0.56       215\n",
      "       perc       0.00      0.00      0.00        11\n",
      "     period       0.86      0.57      0.69        21\n",
      "      plant       0.00      0.00      0.00         3\n",
      "    product       0.50      0.27      0.35        11\n",
      "     reason       0.95      0.75      0.84        73\n",
      "   religion       0.00      0.00      0.00         3\n",
      "      speed       0.00      0.00      0.00         4\n",
      "      sport       0.78      0.37      0.50        19\n",
      "      state       0.84      0.88      0.86        24\n",
      "  substance       0.50      0.19      0.27        16\n",
      "     symbol       1.00      0.50      0.67         2\n",
      "   techmeth       0.62      0.42      0.50        12\n",
      "       temp       1.00      0.20      0.33         5\n",
      "     termeq       0.41      0.38      0.39        29\n",
      "      title       1.00      0.38      0.55         8\n",
      "        veh       0.00      0.00      0.00        12\n",
      "    volsize       1.00      0.20      0.33         5\n",
      "     weight       1.00      0.33      0.50         3\n",
      "       word       0.67      0.25      0.36         8\n",
      "\n",
      "avg / total       0.70      0.69      0.67      3544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Archana\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Archana\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_tf, y, test_size=0.33)\n",
    "\n",
    "classifier = LabelPowerset(RandomForestClassifier())\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_test,predictions))\n",
    "\n",
    "print(\"Hamming Loss = \", metrics.hamming_loss(y_test, predictions))\n",
    "\n",
    "print('Classification Report: ')\n",
    "print(classification_report(y_test,predictions, target_names = classes_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.348758465011\n",
      "Hamming Loss =  0.021231739000809234\n",
      "Classification Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       ABBR       0.75      0.44      0.56        27\n",
      "       DESC       0.89      0.60      0.72       388\n",
      "       ENTY       0.90      0.41      0.57       401\n",
      "        HUM       0.93      0.58      0.71       402\n",
      "        LOC       0.91      0.69      0.78       259\n",
      "        NUM       0.98      0.68      0.81       295\n",
      "        abb       1.00      0.14      0.25         7\n",
      "     animal       0.83      0.14      0.24        35\n",
      "       body       0.00      0.00      0.00         7\n",
      "       city       1.00      0.25      0.40        44\n",
      "       code       0.00      0.00      0.00         0\n",
      "      color       0.00      0.00      0.00        13\n",
      "      count       0.98      0.88      0.93       120\n",
      "    country       0.88      0.52      0.66        44\n",
      "     cremat       0.80      0.17      0.29        69\n",
      "   currency       0.00      0.00      0.00         2\n",
      "       date       1.00      0.31      0.47        78\n",
      "        def       0.82      0.55      0.66       139\n",
      "       desc       0.85      0.34      0.48       101\n",
      "     dismed       1.00      0.55      0.71        31\n",
      "       dist       0.00      0.00      0.00        10\n",
      "      event       1.00      0.05      0.09        21\n",
      "        exp       0.75      0.45      0.56        20\n",
      "       food       1.00      0.22      0.36        32\n",
      "         gr       0.20      0.02      0.04        49\n",
      "        ind       0.97      0.48      0.65       328\n",
      "     instru       0.00      0.00      0.00         4\n",
      "       lang       1.00      0.25      0.40         8\n",
      "     letter       0.00      0.00      0.00         3\n",
      "     manner       0.98      0.49      0.65        92\n",
      "      money       1.00      0.26      0.41        23\n",
      "      mount       0.00      0.00      0.00         7\n",
      "        ord       0.00      0.00      0.00         1\n",
      "      other       0.85      0.42      0.56       215\n",
      "       perc       1.00      0.09      0.17        11\n",
      "     period       1.00      0.14      0.25        21\n",
      "      plant       0.00      0.00      0.00         3\n",
      "    product       0.00      0.00      0.00        11\n",
      "     reason       1.00      0.58      0.73        73\n",
      "   religion       0.00      0.00      0.00         3\n",
      "      speed       0.00      0.00      0.00         4\n",
      "      sport       1.00      0.05      0.10        19\n",
      "      state       0.00      0.00      0.00        24\n",
      "  substance       0.00      0.00      0.00        16\n",
      "     symbol       0.00      0.00      0.00         2\n",
      "   techmeth       0.40      0.17      0.24        12\n",
      "       temp       1.00      0.20      0.33         5\n",
      "     termeq       0.00      0.00      0.00        29\n",
      "      title       1.00      0.25      0.40         8\n",
      "        veh       0.00      0.00      0.00        12\n",
      "    volsize       0.00      0.00      0.00         5\n",
      "     weight       1.00      0.33      0.50         3\n",
      "       word       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.87      0.48      0.60      3544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Archana\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Archana\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_tf, y, test_size=0.33)\n",
    "\n",
    "classifier = BinaryRelevance(RandomForestClassifier())\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \", metrics.accuracy_score(y_test,predictions))\n",
    "\n",
    "print(\"Hamming Loss = \", metrics.hamming_loss(y_test, predictions))\n",
    "\n",
    "print('Classification Report: ')\n",
    "print(classification_report(y_test,predictions, target_names = classes_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast Text supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('d_train_fasttext.txt', \"w\", encoding='utf-8').close()\n",
    "\n",
    "output = open('d_train_fasttext.txt', \"w\", encoding='utf-8')\n",
    "\n",
    "for i in range(len(questions[:3000])):\n",
    "\n",
    "    s = '__label__' + intent_set[i] + ',' + label_set[i]  + ' ' + questions[i] + \"\\n\"\n",
    "    \n",
    "    output.write(s)\n",
    "    \n",
    "output.flush()\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "open('d_test_fasttext.txt', \"w\", encoding='utf-8').close()\n",
    "\n",
    "output = open('d_test_fasttext.txt', \"w\", encoding='utf-8')\n",
    "\n",
    "for i in range(len(questions[3000:])):\n",
    "\n",
    "    s = '__label__' + intent_set[i] + ',' + label_set[i]  + ' ' + questions[i] + \"\\n\"\n",
    "    \n",
    "    output.write(s)\n",
    "    \n",
    "output.flush()\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fastText as ft\n",
    "\n",
    "model = ft.train_supervised('d_train_fasttext.txt', epoch=50)\n",
    "\n",
    "result = model.test('d_test_fasttext.txt')\n",
    "\n",
    "print (result)\n",
    "\n",
    "# output:  Precision: 0.9662304769945125, Recall: 0.9662304769945125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = model.predict('Who are the Lakers team ?')\n",
    "print (label)\n",
    "\n",
    "# output: ('__label__HUM,gr',)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
